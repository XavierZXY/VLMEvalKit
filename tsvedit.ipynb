{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Step 2: Open and read the JSON file\n",
    "with open(\"query.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Step 4: Open a new TSV file for writing\n",
    "with open(\"output.tsv\", \"w\", newline=\"\", encoding=\"utf-8\") as tsv_file:\n",
    "    writer = csv.writer(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "    # Step 5: Write the headers to the TSV file\n",
    "    headers = [\"index\", \"question\", \"answer\", \"class\", \"image\", \"support\"]\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Step 6: Iterate over each item in the JSON data\n",
    "    for item in data:\n",
    "        # Step 7: Extract the required fields\n",
    "        row = [\n",
    "            item.get(\"id\", \"\"),\n",
    "            item.get(\"question\", \"\"),\n",
    "            item.get(\"answer\", \"\"),\n",
    "            item.get(\"classes\", \"\"),\n",
    "            item.get(\"image\", \"\"),\n",
    "            item.get(\"support\", \"\"),\n",
    "        ]\n",
    "        # Step 8: Write the extracted fields to the TSV file\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file with base64 encoded images has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import base64\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "# 获取上级目录\n",
    "# parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "# 将上级目录添加到sys.path中\n",
    "sys.path.append(current_dir)\n",
    "# 现在可以导入上级目录中的包\n",
    "from vlmeval.smp.vlm import *\n",
    "# 读取TSV文件并解析数据\n",
    "input_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/Open_MI.tsv\"\n",
    "output_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/Open_MI_new.tsv\"\n",
    "\n",
    "\n",
    "# def image_to_base64(image_path):\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "data = []\n",
    "count = 0\n",
    "with open(input_tsv, \"r\", encoding=\"utf-8\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    headers = next(tsvreader)\n",
    "    data.append(headers)  # 保留headers\n",
    "    for row in tsvreader:\n",
    "        # image_path = os.path.join(os.path.dirname(input_tsv), row[headers.index(\"image\")].strip(\"[]\").strip(\"'\"))\n",
    "        # row[headers.index(\"image\")] = encode_image_file_to_base64(image_path)\n",
    "        support = eval(row[headers.index(\"support\")])\n",
    "        for key in support:\n",
    "            support[key]['images'] = [encode_image_file_to_base64(os.path.join(os.path.dirname(input_tsv), img_path)) for img_path in support[key]['images']]\n",
    "        row[headers.index(\"support\")] = str(support)\n",
    "        data.append(row)\n",
    "\n",
    "# # 将修改后的数据写回到一个新的TSV文件中\n",
    "with open(output_tsv, \"w\", encoding=\"utf-8\", newline=\"\") as tsvfile:\n",
    "    tsvwriter = csv.writer(tsvfile, delimiter=\"\\t\")\n",
    "    tsvwriter.writerows(data)\n",
    "\n",
    "print(\"TSV file with base64 encoded images has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file with renamed support images has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# 读取TSV文件并解析数据\n",
    "input_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/Open_MI.tsv.bp\"\n",
    "output_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/Open_MI.tsv.path\"\n",
    "\n",
    "csv.field_size_limit(100000000)  # Increase the field size limit\n",
    "\n",
    "data = []\n",
    "with open(input_tsv, \"r\", encoding=\"utf-8\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    headers = next(tsvreader)\n",
    "    data.append(headers)  # 保留headers\n",
    "    for row in tsvreader:\n",
    "        support = eval(row[headers.index(\"support\")])\n",
    "        for key in support:\n",
    "            support[key]['image_path'] = [img.replace(\"open_mi/\", \"\") for img in support[key].pop('images')]\n",
    "        row[headers.index(\"support\")] = json.dumps(support)\n",
    "        data.append(row)\n",
    "\n",
    "# 将修改后的数据写回到一个新的TSV文件中\n",
    "with open(output_tsv, \"w\", encoding=\"utf-8\", newline=\"\") as tsvfile:\n",
    "    tsvwriter = csv.writer(tsvfile, delimiter=\"\\t\")\n",
    "    tsvwriter.writerows(data)\n",
    "\n",
    "print(\"TSV file with renamed support images has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge path and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file with merged support image paths has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# 读取TSV文件并解析数据\n",
    "input_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/Open_MI.tsv\"\n",
    "input_tsv_path = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/Open_MI.tsv.path\"\n",
    "output_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/Open_MI.tsv.merge\"\n",
    "\n",
    "csv.field_size_limit(100000000)  # Increase the field size limit\n",
    "\n",
    "data = []\n",
    "with open(input_tsv, \"r\", encoding=\"utf-8\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    headers = next(tsvreader)\n",
    "    data.append(headers)  # 保留headers\n",
    "    for row in tsvreader:\n",
    "        data.append(row)\n",
    "        \n",
    "data_path = []\n",
    "with open(input_tsv_path, \"r\", encoding=\"utf-8\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    headers_path = next(tsvreader)\n",
    "    data_path.append(headers_path)  # 保留headers\n",
    "    for row in tsvreader:\n",
    "        data_path.append(row)\n",
    "        \n",
    "for i in range(1, len(data)):\n",
    "    support = json.loads(data[i][headers.index(\"support\")])\n",
    "    support_path = json.loads(data_path[i][headers_path.index(\"support\")])\n",
    "    for key in support:\n",
    "        support[key]['image_path'] = support_path[key]['image_path']\n",
    "    data[i][headers.index(\"support\")] = json.dumps(support)\n",
    "    \n",
    "with open(output_tsv, \"w\", encoding=\"utf-8\", newline=\"\") as tsvfile:\n",
    "    tsvwriter = csv.writer(tsvfile, delimiter=\"\\t\")\n",
    "    tsvwriter.writerows(data)\n",
    "\n",
    "print(\"TSV file with merged support image paths has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clevr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json to tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "query_json = os.getcwd()+\"/datasets/clevr/query.json\"\n",
    "support_json = os.getcwd()+\"/datasets/clevr/support.json\"\n",
    "output_tsv = os.getcwd()+\"/datasets/clevr/clevr.tsv\"\n",
    "\n",
    "# Step 2: Open and read the JSON file\n",
    "with open(query_json, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    query_data = json.load(json_file)\n",
    "    \n",
    "with open(support_json, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    support_data = json.load(json_file)\n",
    "    \n",
    "# Step 3: Combine every four items in support_data\n",
    "combined_support_data = []\n",
    "for i in range(0, len(support_data), 4):\n",
    "    combined_support = support_data[i:i+4]\n",
    "    combined_support_data.append(combined_support)\n",
    "    \n",
    "\n",
    "\n",
    "# Step 4: Open a new TSV file for writing\n",
    "with open(output_tsv, \"w\", newline=\"\", encoding=\"utf-8\") as tsv_file:\n",
    "    writer = csv.writer(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "    # Step 5: Write the headers to the TSV file\n",
    "    headers = [\"index\", \"question\", \"answer\", \"image\", \"support\"]\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Step 6: Iterate over each item in the JSON data\n",
    "    for idx, item in enumerate(query_data):\n",
    "        # Step 7: Extract the required fields\n",
    "        row = [\n",
    "            item.get(\"id\", \"\"),\n",
    "            item.get(\"question\", \"\"),\n",
    "            item.get(\"answer\", \"\"),\n",
    "            item.get(\"image\", \"\"),\n",
    "            combined_support_data[idx % len(combined_support_data)] if combined_support_data else \"\"\n",
    "        ]\n",
    "        # Step 8: Write the extracted fields to the TSV file\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image paht to base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file with base64 encoded images has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import base64\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "# 将上级目录添加到sys.path中\n",
    "sys.path.append(current_dir)\n",
    "# 现在可以导入上级目录中的包\n",
    "from vlmeval.smp.vlm import *\n",
    "# 读取TSV文件并解析数据\n",
    "input_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/clevr.tsv\"\n",
    "output_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/clevr_new.tsv\"\n",
    "\n",
    "data = []\n",
    "count = 0\n",
    "with open(input_tsv, \"r\", encoding=\"utf-8\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    headers = next(tsvreader)\n",
    "    data.append(headers)  # 保留headers\n",
    "    for row in tsvreader:\n",
    "        # image_path = os.path.join(os.path.dirname(input_tsv), row[headers.index(\"image\")].strip(\"[]\").strip(\"'\"))\n",
    "        # row[headers.index(\"image\")] = encode_image_file_to_base64(image_path)\n",
    "        datadir = os.path.join(os.getcwd(), \"datasets\")\n",
    "        row[headers.index(\"image\")] = encode_image_file_to_base64(os.path.join(datadir, row[headers.index(\"image\")].strip(\"[]\").strip(\"'\")))\n",
    "        support = eval(row[headers.index(\"support\")])\n",
    "        support = eval(row[headers.index(\"support\")])\n",
    "        for item in support:\n",
    "            item['image'] = [encode_image_file_to_base64(os.path.join(datadir, img)) for img in item['image']]\n",
    "        row[headers.index(\"support\")] = json.dumps(support)\n",
    "        data.append(row)\n",
    "\n",
    "# # 将修改后的数据写回到一个新的TSV文件中\n",
    "with open(output_tsv, \"w\", encoding=\"utf-8\", newline=\"\") as tsvfile:\n",
    "    tsvwriter = csv.writer(tsvfile, delimiter=\"\\t\")\n",
    "    tsvwriter.writerows(data)\n",
    "\n",
    "print(\"TSV file with base64 encoded images has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file with base64 encoded images has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import base64\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "# 将上级目录添加到sys.path中\n",
    "sys.path.append(current_dir)\n",
    "# 现在可以导入上级目录中的包\n",
    "from vlmeval.smp.vlm import *\n",
    "# 读取TSV文件并解析数据\n",
    "input_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/CLEVR.tsv\"\n",
    "output_tsv = \"/home/zxy/codes/working/ICLBoom/VLMEvalKit/LMUData/CLEVR_new.tsv\"\n",
    "\n",
    "data = []\n",
    "count = 0\n",
    "with open(input_tsv, \"r\", encoding=\"utf-8\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    headers = next(tsvreader)\n",
    "    data.append(headers)  # 保留headers\n",
    "    for row in tsvreader:\n",
    "        support = eval(row[headers.index(\"support\")])\n",
    "        for item in support:\n",
    "            if \"id\" in item:\n",
    "                item[\"index\"] = item.pop(\"id\")\n",
    "        row[headers.index(\"support\")] = json.dumps(support)\n",
    "                    \n",
    "        data.append(row)\n",
    "\n",
    "# # 将修改后的数据写回到一个新的TSV文件中\n",
    "with open(output_tsv, \"w\", encoding=\"utf-8\", newline=\"\") as tsvfile:\n",
    "    tsvwriter = csv.writer(tsvfile, delimiter=\"\\t\")\n",
    "    tsvwriter.writerows(data)\n",
    "\n",
    "print(\"TSV file with base64 encoded images has been created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
